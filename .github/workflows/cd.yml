name: Databricks AWS Setup
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
jobs:
  create-aws-resource:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ secrets.AWS_DEFAULT_REGION }}

    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - uses: actions/setup-python@v4

      - name: AWS S3 Copy Source Data
        uses: jakejarvis/s3-sync-action@v0.5.0
        with:
          args: --follow-symlinks
        env:
          AWS_S3_BUCKET: "data-engg-onboarding"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1
        with:
          terraform_version: 1.5.6

      - name: Set Terraform Variables
        run: |
          export TF_VAR_databricks_account_username="${{ secrets.DATABRICKS_ACCOUNT_USERNAME }}"
          export TF_VAR_databricks_account_password="${{ secrets.DATABRICKS_ACCOUNT_PASSWORD }}"
          export TF_VAR_databricks_account_id="${{ secrets.DATABRICKS_ACCOUNT_ID }}"
          export TF_VAR_AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID}}"
          export TF_VAR_AWS_SECRET_ACCESS_KEY="${{secrets.AWS_SECRET_ACCESS_KEY}}"
          export TF_VAR_email=${{secrets.AWS_SNS_EMAIL}}

      - name: Terraform Init (AWS Resource)
        run: |
          cd dbt_gx/aws_resources
          terraform init

      - name: Plan and Apply AWS resources
        run: |
          cd dbt_gx/aws_resources
          terraform validate
          terraform plan
        id: aws_outputs

      - name: Terraform Init (Databricks)
        run: |
          cd dbt_gx/dbt_workspace
          terraform init

      - name: Plan and Apply Databricks workspace
        run: |
          cd dbt_gx/dbt_workspace
          terraform validate
          terraform plan
        id: databricks_outputs

      - name: Store Terraform Outputs in S3
        run: |
          echo "S3 Bucket name ${{ steps.s3_bucket_name.outputs.s3_bucket_name }}" 
          S3_BUCKET_NAME=${{ steps.s3_bucket_name.outputs.s3_bucket_name }}
          # aws s3 cp dbt_gx/aws_resources/terraform.tfstate s3://your-s3-bucket-name/
          # aws s3 cp dbt_gx/dbt_workspace/terraform.tfstate s3://your-s3-bucket-name/

      - name: Destroy AWS Resources
        run: |
          cd dbt_gx/aws_resources
          terraform destroy

      - name: Destroy Databricks Resources
        run: |
          cd dbt_gx/dbt_workspace
          terraform destroy

      - name: Use Terraform Outputs
        run: |
          echo "SNS Topic ARN: ${{ steps.aws_outputs.outputs.sns_topic_arn }}"
          echo "S3 Bucket Name: ${{ steps.databricks_outputs.outputs.databricks_host }}"
          echo "Lambda Function ARN: ${{ steps.databricks_outputs.outputs.databricks_token }}"

          echo "::set-env name=SNS_TOPIC_ARN::${{ steps.aws_outputs.outputs.sns_topic_arn }}"
          echo "::set-env name=DATABRICKS_HOST::${{ steps.databricks_outputs.outputs.databricks_host }}"
          echo "::set-env name=DATABRICKS_TOKEN::${{ steps.databricks_outputs.outputs.databricks_token }}"

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: 16.x

      - name: Setup Serverless Framework & Build
        run: |
          npm install -g serverless
          cd dbt_gx
          serverless package

      # - name: Deploy Lambda using AWS CLI
      #   uses: ItsKarma/aws-cli@v1.70.0
      #   with:
      #     args: lambda update-function-code --function-name ${{ secrets.AWS_LAMBDA_NAME }} --zip-file fileb://dbt_gx/.serverless/generate-report.zip
      #   env:
      #     AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      #     AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      #     AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}

      - name: Update Lambda Environment Variables
        run: aws lambda update-function-configuration --function-name ${{ secrets.AWS_LAMBDA_NAME }} --environment "Variables={ARN_VALUE='SOME_RANDOM_VALUE'}"

      - name: Run Cluster Script
        run: |
          cd dbt_gx
          pip install databricks_api
          python3 cluster.py
